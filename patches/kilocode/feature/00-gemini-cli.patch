file packages/core-schemas/src/config/provider.ts
label export const geminiProviderSchema = baseProviderSchema.extend({

 	enableGrounding: z.boolean().optional(),
 })
 
+// Gemini CLI provider
+export const geminiCliProviderSchema = baseProviderSchema.extend({
+	provider: z.literal("gemini-cli"),
+	apiModelId: z.string().optional(),
+	geminiCliOAuthPath: z.string().optional(),
+	geminiCliProjectId: z.string().optional(),
+})
+
 // Mistral provider
 export const mistralProviderSchema = baseProviderSchema.extend({
 	provider: z.literal("mistral"),

label export const providerConfigSchema = z.discriminatedUnion("provider", [

 	bedrockProviderSchema,
 	vertexProviderSchema,
 	geminiProviderSchema,
+	geminiCliProviderSchema,
 	mistralProviderSchema,
 	moonshotProviderSchema,
 	minimaxProviderSchema,

label export type InceptionProviderConfig = z.infer<typeof inceptionProviderSchema>

 export type BedrockProviderConfig = z.infer<typeof bedrockProviderSchema>
 export type VertexProviderConfig = z.infer<typeof vertexProviderSchema>
 export type GeminiProviderConfig = z.infer<typeof geminiProviderSchema>
+export type GeminiCliProviderConfig = z.infer<typeof geminiCliProviderSchema>
 export type MistralProviderConfig = z.infer<typeof mistralProviderSchema>
 export type MoonshotProviderConfig = z.infer<typeof moonshotProviderSchema>
 export type MinimaxProviderConfig = z.infer<typeof minimaxProviderSchema>

file packages/types/src/provider-settings.ts
label export const providerNames = [

 	"featherless",
 	"fireworks",
 	"gemini",
+	"gemini-cli",
 	"groq",
 	"mistral",
 	"moonshot",
 	"minimax",
 	"openai-codex",
 	"openai-native",
 	"openai-responses", // kilocode_change
 	"qwen-code",
 	"roo",
 	// kilocode_change start
 	"kilocode",
 	"minimax",
+	"gemini-cli",
 	"virtual-quota-fallback",

 	"inception",

label const geminiSchema = apiModelIdProviderModelSchema.extend({

 	enableGrounding: z.boolean().optional(),
 })
 
+const geminiCliSchema = apiModelIdProviderModelSchema.extend({
+	geminiCliOAuthPath: z.string().optional(),
+	geminiCliProjectId: z.string().optional(),
+})
+
 const openAiCodexSchema = apiModelIdProviderModelSchema.extend({
 	// No additional settings needed - uses OAuth authentication
 })

label export const providerSettingsSchemaDiscriminated = z.discriminatedUnion("apiProv

 	fakeAiSchema.merge(z.object({ apiProvider: z.literal("fake-ai") })),
 	xaiSchema.merge(z.object({ apiProvider: z.literal("xai") })),
 	// kilocode_change start
+	geminiCliSchema.merge(z.object({ apiProvider: z.literal("gemini-cli") })),

 	virtualQuotaFallbackSchema.merge(z.object({ apiProvider: z.literal("virtual-quota-fallback") })),
 	syntheticSchema.merge(z.object({ apiProvider: z.literal("synthetic") })),

label export const providerSettingsSchema = z.object({

 	...lmStudioSchema.shape,
 	...geminiSchema.shape,
 	// kilocode_change start
+	...geminiCliSchema.shape,

 	...virtualQuotaFallbackSchema.shape,
 	...syntheticSchema.shape,

label export const modelIdKeysByProvider: Record<TypicalProvider, ModelIdKey> = {

 	ollama: "ollamaModelId",
 	lmstudio: "lmStudioModelId",
 	gemini: "apiModelId",
+	"gemini-cli": "apiModelId",
 	mistral: "apiModelId",
 	moonshot: "apiModelId",
 	minimax: "apiModelId",

label export const MODELS_BY_PROVIDER: Record<

 		| "openai"
 		| "openai-responses" // kilocode_change
 		| "gemini"
+    | "gemini-cli"
 	>,
 	{ id: ProviderName; label: string; models: string[] }
 > = {

file packages/types/src/providers/gemini-cli.ts

+import type { ModelInfo } from '../model.js';
+
+export type GeminiCliModelId = keyof typeof geminiCliModels;
+export const geminiCliDefaultModelId: GeminiCliModelId = 'gemini-2.5-flash';
+export const geminiCliModels = {
+  'gemini-3-pro-preview': {
+    maxTokens: 65_536,
+    contextWindow: 1_048_576,
+    supportsImages: true,
+    supportsPromptCache: true,
+    supportsNativeTools: true,
+    defaultToolProtocol: 'native',
+    supportsReasoningEffort: ['low', 'high'],
+    reasoningEffort: 'low',
+    supportsTemperature: true,
+    defaultTemperature: 1,
+    inputPrice: 0,
+    outputPrice: 0,
+    maxThinkingTokens: 65_536,
+  },
+  'gemini-3-flash-preview': {
+    maxTokens: 65_536,
+    contextWindow: 1_048_576,
+    supportsImages: true,
+    supportsPromptCache: true,
+    supportsNativeTools: true,
+    defaultToolProtocol: 'native',
+    supportsReasoningEffort: ['minimal', 'low', 'medium', 'high'],
+    reasoningEffort: 'medium',
+    supportsTemperature: true,
+    defaultTemperature: 1,
+    inputPrice: 0,
+    outputPrice: 0,
+    maxThinkingTokens: 65_536,
+  },
+  'gemini-2.5-pro': {
+    maxTokens: 64_000,
+    contextWindow: 1_048_576,
+    supportsImages: true,
+    supportsPromptCache: true,
+    supportsNativeTools: true,
+    defaultToolProtocol: 'native',
+    supportsReasoningBudget: true,
+    requiredReasoningBudget: true,
+    inputPrice: 0,
+    outputPrice: 0,
+    maxThinkingTokens: 32_768,
+  },
+  'gemini-2.5-flash': {
+    maxTokens: 64_000,
+    contextWindow: 1_048_576,
+    supportsImages: true,
+    supportsPromptCache: true,
+    supportsNativeTools: true,
+    defaultToolProtocol: 'native',
+    supportsReasoningBudget: true,
+    requiredReasoningBudget: true,
+    inputPrice: 0,
+    outputPrice: 0,
+    maxThinkingTokens: 32_768,
+  },
+  'gemini-2.5-flash-lite': {
+    maxTokens: 64_000,
+    contextWindow: 1_048_576,
+    supportsImages: true,
+    supportsPromptCache: true,
+    supportsNativeTools: true,
+    defaultToolProtocol: 'native',
+    supportsReasoningBudget: true,
+    requiredReasoningBudget: true,
+    inputPrice: 0,
+    outputPrice: 0,
+    maxThinkingTokens: 32_768,
+  },
+} as const satisfies Record<string, ModelInfo>;

file packages/types/src/providers/index.ts
label export * from "./featherless.js"

 export * from "./fireworks.js"
 export * from "./gemini.js"
 // kilocode_change start
+export * from "./gemini-cli.js"
 export * from "./ovhcloud.js"
 export * from "./synthetic.js"
 export * from "./inception.js"

label export function getProviderDefaultModelId(

 		case "vercel-ai-gateway":
 			return vercelAiGatewayDefaultModelId
 		case "anthropic":
+		case "gemini-cli":
 		case "human-relay":
 		case "fake-ai":
 		default:

file src/api/index.ts
label import {

 	LiteLLMHandler,
 	// kilocode_change start
 	VirtualQuotaFallbackHandler,
+	GeminiCliHandler,
 	SyntheticHandler,
 	OVHcloudAIEndpointsHandler,
 	SapAiCoreHandler,

label export function buildApiHandler(configuration: ProviderSettings): ApiHandler {

 		// kilocode_change start
 		case "kilocode":
 			return new KilocodeOpenrouterHandler(options)
+		case "gemini-cli":
+			return new GeminiCliHandler(options)
 		case "virtual-quota-fallback":
 			return new VirtualQuotaFallbackHandler(options)
 		// kilocode_change end

file src/api/providers/gemini-cli.ts

+import { FunctionCallingConfigMode } from '@google/genai';
+import { geminiCliDefaultModelId, geminiCliModels } from '@roo-code/types';
+import { readFile, writeFile } from 'fs/promises';
+import { OAuth2Client } from 'google-auth-library';
+import { homedir } from 'node:os';
+import { dirname, join } from 'node:path';
+import { convertAnthropicMessageToGemini } from '../transform/gemini-format';
+import { getModelParams } from '../transform/model-params';
+import { BaseProvider } from './base-provider';
+
+import type { Anthropic } from '@anthropic-ai/sdk';
+import type { GeminiCliModelId } from '@roo-code/types';
+import type { ApiHandlerOptions } from '../../shared/api';
+import type { ApiHandlerCreateMessageMetadata, SingleCompletionHandler } from '../index';
+import type { ApiStream } from '../transform/stream';
+
+const CODE_ASSIST_ENDPOINT = 'https://cloudcode-pa.googleapis.com';
+const CODE_ASSIST_API_VERSION = 'v1internal';
+const OAUTH_CLIENT_ID = '681255809395-oo8ft2oprdrnp9e3aqf6av3hmdib135j.apps.googleusercontent.com';
+const OAUTH_CLIENT_SECRET = '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';
+const OAUTH_REDIRECT_URI = 'http://localhost:45289';
+const TOKEN_EXPIRY_BUFFER_MS = 60_000;
+
+interface OAuthCredentials {
+  readonly access_token: string;
+  readonly refresh_token: string;
+  readonly token_type: string;
+  readonly expiry_date: number;
+}
+
+export class GeminiCliHandler extends BaseProvider implements SingleCompletionHandler {
+  protected options: ApiHandlerOptions;
+  private authClient: OAuth2Client;
+  private credentials?: OAuthCredentials;
+  private projectId?: string;
+  private lastResponseId?: string;
+  private lastThoughtSignature?: string;
+  private readonly credPath: string;
+
+  public constructor(options: ApiHandlerOptions) {
+    super();
+    this.options = options;
+    this.authClient = new OAuth2Client(OAUTH_CLIENT_ID, OAUTH_CLIENT_SECRET, OAUTH_REDIRECT_URI);
+    this.credPath = options.geminiCliOAuthPath || join(homedir(), '.gemini', 'oauth_creds.json');
+  }
+
+  public async *createMessage(
+    systemInstruction: string,
+    messages: Anthropic.Messages.MessageParam[],
+    metadata?: ApiHandlerCreateMessageMetadata,
+  ): ApiStream {
+    const { id: model, info, reasoning: thinkingConfig, maxTokens } = this.getModel();
+    this.lastResponseId = undefined;
+    this.lastThoughtSignature = undefined;
+
+    const isHybridReasoningModel = info.supportsReasoningBudget || info.requiredReasoningBudget;
+    const maxOutputTokens = isHybridReasoningModel ? (this.options.modelMaxTokens ?? maxTokens ?? undefined) : (maxTokens ?? undefined);
+
+    const usingNativeTools = Boolean(metadata?.tools && metadata.tools.length > 0);
+    const includeThoughtSignatures = Boolean(thinkingConfig) || usingNativeTools;
+
+    const geminiMessages = messages.filter((message): message is Anthropic.Messages.MessageParam => {
+      const meta = message as { type?: string };
+      if (meta.type === 'reasoning') {
+        return false;
+      }
+      return true;
+    });
+
+    const toolIdToName = new Map<string, string>();
+    for (const message of messages) {
+      if (Array.isArray(message.content)) {
+        for (const block of message.content) {
+          if (block.type === 'tool_use') {
+            toolIdToName.set(block.id, block.name);
+          }
+        }
+      }
+    }
+
+    const contents = geminiMessages.map((message) => convertAnthropicMessageToGemini(message, { includeThoughtSignatures, toolIdToName })).flat();
+
+    const supportsTemperature = info.supportsTemperature !== false;
+    const temperatureConfig: number | undefined = supportsTemperature
+      ? (this.options.modelTemperature ?? info.defaultTemperature ?? 1)
+      : info.defaultTemperature;
+
+    await this.ensureAuthenticated();
+    await this.discoverProjectId();
+
+    const requestBody: any = {
+      model,
+      project: this.projectId,
+      request: {
+        systemInstruction: {
+          parts: [{ text: systemInstruction }],
+        },
+        contents,
+        generationConfig: {
+          temperature: temperatureConfig,
+          maxOutputTokens,
+          ...(thinkingConfig ? { thinkingConfig } : {}),
+        },
+      },
+    };
+
+    if (this.shouldIncludeTools(info, metadata)) {
+      requestBody.request.tools = [
+        {
+          functionDeclarations: metadata!.tools!.map((tool) => ({
+            name: (tool as any).function.name,
+            description: (tool as any).function.description,
+            parametersJsonSchema: (tool as any).function.parameters,
+          })),
+        },
+      ];
+
+      if (metadata?.allowedFunctionNames && metadata.allowedFunctionNames.length > 0) {
+        requestBody.request.toolConfig = {
+          functionCallingConfig: {
+            mode: FunctionCallingConfigMode.ANY,
+            allowedFunctionNames: metadata.allowedFunctionNames,
+          },
+        };
+      } else if (metadata?.tool_choice) {
+        const choice = metadata.tool_choice;
+        let mode = FunctionCallingConfigMode.AUTO;
+        let allowedFunctionNames: string[] | undefined;
+
+        if (choice === 'none') {
+          mode = FunctionCallingConfigMode.NONE;
+        } else if (choice === 'required') {
+          mode = FunctionCallingConfigMode.ANY;
+        } else if (typeof choice === 'object' && choice.type === 'function') {
+          mode = FunctionCallingConfigMode.ANY;
+          allowedFunctionNames = [choice.function.name];
+        }
+
+        requestBody.request.toolConfig = {
+          functionCallingConfig: { mode, ...(allowedFunctionNames ? { allowedFunctionNames } : {}) },
+        };
+      }
+    }
+
+    const controller = new AbortController();
+    const response = await this.authClient.request({
+      url: this.getApiUrl('streamGenerateContent'),
+      method: 'POST',
+      params: { alt: 'sse' },
+      headers: { 'Content-Type': 'application/json' },
+      responseType: 'stream',
+      data: requestBody,
+      signal: controller.signal,
+    });
+
+    let lastUsage: any;
+    let toolCallCounter = 0;
+
+    try {
+      const stream = this.parseSSEStream(response.data as NodeJS.ReadableStream);
+      for await (const jsonData of stream) {
+        const responseData = jsonData.response || jsonData;
+        const candidate = responseData.candidates?.[0];
+
+        if (responseData.responseId) {
+          this.lastResponseId = responseData.responseId;
+        }
+
+        if (candidate?.content?.parts) {
+          for (const part of candidate.content.parts) {
+            const thoughtSignature = part.thoughtSignature;
+            if (includeThoughtSignatures && thoughtSignature) {
+              this.lastThoughtSignature = thoughtSignature;
+            }
+
+            if (part.thought) {
+              if (part.text) {
+                yield { type: 'reasoning', text: part.text };
+              }
+            } else if (part.functionCall) {
+              const callId = `${part.functionCall.name}-${toolCallCounter}`;
+              const args = JSON.stringify(part.functionCall.args || {});
+
+              yield {
+                type: 'tool_call_partial',
+                index: toolCallCounter,
+                id: callId,
+                name: part.functionCall.name,
+                arguments: undefined,
+              };
+
+              yield {
+                type: 'tool_call_partial',
+                index: toolCallCounter,
+                id: callId,
+                name: undefined,
+                arguments: args,
+              };
+
+              toolCallCounter++;
+            } else if (part.text) {
+              yield { type: 'text', text: part.text };
+            }
+          }
+        }
+        if (responseData.usageMetadata) lastUsage = responseData.usageMetadata;
+        if (candidate?.finishReason) break;
+      }
+    } finally {
+      controller.abort();
+    }
+
+    if (lastUsage) {
+      yield {
+        type: 'usage',
+        inputTokens: lastUsage.promptTokenCount ?? 0,
+        outputTokens: lastUsage.candidatesTokenCount ?? 0,
+        cacheReadTokens: lastUsage.cachedContentTokenCount,
+        reasoningTokens: lastUsage.thoughtsTokenCount,
+        totalCost: 0,
+      };
+    }
+  }
+
+  public async completePrompt(prompt: string): Promise<string> {
+    const { id: model, info } = this.getModel();
+
+    const supportsTemperature = info.supportsTemperature !== false;
+    const temperatureConfig: number | undefined = supportsTemperature
+      ? (this.options.modelTemperature ?? info.defaultTemperature ?? 1)
+      : info.defaultTemperature;
+
+    await this.ensureAuthenticated();
+    await this.discoverProjectId();
+
+    const requestBody = {
+      model,
+      project: this.projectId,
+      request: {
+        contents: [{ role: 'user', parts: [{ text: prompt }] }],
+        generationConfig: { temperature: temperatureConfig },
+      },
+    };
+
+    const response = await this.authClient.request({
+      url: this.getApiUrl('generateContent'),
+      method: 'POST',
+      headers: { 'Content-Type': 'application/json' },
+      data: requestBody,
+    });
+
+    const responseData = (response.data as any).response || response.data;
+    return (
+      responseData.candidates?.[0]?.content?.parts
+        ?.filter((p: any) => p.text && !p.thought)
+        ?.map((p: any) => p.text)
+        ?.join('') || ''
+    );
+  }
+
+  public getThoughtSignature(): string | undefined {
+    return this.lastThoughtSignature;
+  }
+
+  public getResponseId(): string | undefined {
+    return this.lastResponseId;
+  }
+
+  public override getModel() {
+    const modelId = this.options.apiModelId?.replace(':thinking', '') || geminiCliDefaultModelId;
+    const id = (modelId in geminiCliModels ? modelId : geminiCliDefaultModelId) as GeminiCliModelId;
+    const info = geminiCliModels[id];
+    return { id, info, ...getModelParams({ format: 'gemini', modelId: id, model: info, settings: this.options }) };
+  }
+
+  private getApiUrl(method: string): string {
+    return `${CODE_ASSIST_ENDPOINT}/${CODE_ASSIST_API_VERSION}:${method}`;
+  }
+
+  private shouldIncludeTools(info: any, metadata?: ApiHandlerCreateMessageMetadata): boolean {
+    return !!(info.supportsNativeTools && metadata?.tools?.length && metadata.toolProtocol !== 'xml');
+  }
+
+  private async ensureAuthenticated(): Promise<void> {
+    if (!this.credentials) {
+      const data = await readFile(this.credPath, 'utf-8');
+      this.credentials = JSON.parse(data);
+      this.authClient.setCredentials(this.credentials!);
+    }
+
+    const isExpired = this.credentials!.expiry_date - TOKEN_EXPIRY_BUFFER_MS < Date.now();
+    if (isExpired) {
+      const { credentials } = await this.authClient.refreshAccessToken();
+      this.credentials = {
+        access_token: credentials.access_token!,
+        refresh_token: credentials.refresh_token || this.credentials!.refresh_token,
+        token_type: credentials.token_type || 'Bearer',
+        expiry_date: credentials.expiry_date || Date.now() + 3600000,
+      };
+      await writeFile(this.credPath, JSON.stringify(this.credentials, null, 2));
+      this.authClient.setCredentials(this.credentials);
+    }
+  }
+
+  private async discoverProjectId(): Promise<void> {
+    if (this.projectId) return;
+
+    const projectIdOptions = this.options.geminiCliProjectId?.trim();
+    if (projectIdOptions) {
+      this.projectId = projectIdOptions;
+      return;
+    }
+
+    if (process.env.GOOGLE_CLOUD_PROJECT) {
+      this.projectId = process.env.GOOGLE_CLOUD_PROJECT;
+      return;
+    }
+
+    try {
+      const envPath = join(dirname(this.credPath), '.env');
+      const content = await readFile(envPath, 'utf-8');
+      const match = content.match(/GOOGLE_CLOUD_PROJECT=["']?([^"'\r\n\s]+)["']?/);
+      if (match) {
+        this.projectId = match[1].trim();
+        return;
+      }
+    } catch {}
+
+    const metadata = {
+      ideType: 'IDE_UNSPECIFIED',
+      platform: 'PLATFORM_UNSPECIFIED',
+      pluginType: 'GEMINI',
+      duetProject: '',
+    };
+
+    try {
+      const load = await this.callEndpoint('loadCodeAssist', { cloudaicompanionProject: '', metadata });
+      if (load.cloudaicompanionProject) {
+        this.projectId = load.cloudaicompanionProject;
+        return;
+      }
+
+      const tierId = load.allowedTiers?.find((t: any) => t.isDefault)?.id || 'free-tier';
+      let onboard = await this.callEndpoint('onboardUser', { tierId, cloudaicompanionProject: '', metadata });
+
+      for (let i = 0; i < 30 && !onboard.done; i++) {
+        await new Promise((r) => setTimeout(r, 2000));
+        onboard = await this.callEndpoint('onboardUser', { tierId, cloudaicompanionProject: '', metadata });
+      }
+      this.projectId = onboard.response?.cloudaicompanionProject?.id || '';
+    } catch (error: any) {
+      throw new Error(`Gemini CLI discoverProjectId failed: ${error.response?.data || error.message}`);
+    }
+  }
+
+  private async callEndpoint(method: string, data: any, retry = true): Promise<any> {
+    try {
+      const res = await this.authClient.request({
+        url: this.getApiUrl(method),
+        method: 'POST',
+        headers: { 'Content-Type': 'application/json' },
+        data,
+      });
+      return res.data;
+    } catch (error: any) {
+      if (error.response?.status === 401 && retry) {
+        await this.ensureAuthenticated();
+        return this.callEndpoint(method, data, false);
+      }
+      throw error;
+    }
+  }
+
+  private async *parseSSEStream(stream: NodeJS.ReadableStream): AsyncGenerator<any> {
+    const decoder = new TextDecoder();
+    let buffer = '';
+
+    for await (const chunk of stream) {
+      buffer += decoder.decode(chunk as Buffer, { stream: true });
+      let boundary = buffer.indexOf('\n');
+
+      while (boundary !== -1) {
+        const line = buffer.slice(0, boundary).trim();
+        buffer = buffer.slice(boundary + 1);
+
+        if (line.startsWith('data: ')) {
+          const data = line.slice(6);
+          if (data === '[DONE]') return;
+          try {
+            yield JSON.parse(data);
+          } catch {}
+        }
+        boundary = buffer.indexOf('\n');
+      }
+    }
+  }
+}

file src/api/providers/index.ts
label export { UnboundHandler } from "./unbound"

 export { VertexHandler } from "./vertex"
 // kilocode_change start
 export { OVHcloudAIEndpointsHandler } from "./ovhcloud"
+export { GeminiCliHandler } from "./gemini-cli"
 export { VirtualQuotaFallbackHandler } from "./virtual-quota-fallback"
 export { SyntheticHandler } from "./synthetic"
 export { InceptionLabsHandler } from "./inception"

file src/shared/checkExistApiConfig.ts
label export function checkExistKey(config: ProviderSettings | undefined) {

 	// Special case for human-relay, fake-ai, claude-code, openai-codex, qwen-code, roo and kilocode providers which don't need any configuration.
 	if (
 		config.apiProvider &&
-		["human-relay", "fake-ai", "claude-code", "openai-codex", "qwen-code", "roo", "kilocode"].includes(
+		["human-relay", "fake-ai", "claude-code", "openai-codex", "qwen-code", "roo", "kilocode", "gemini-cli"].includes(
 			config.apiProvider,
 		) // kilocode_change: add kilocode for anonymous access
 	) {

file webview-ui/src/components/kilocode/hooks/useProviderModels.ts
label import {

 	litellmDefaultModelId,
 	qwenCodeModels,
 	qwenCodeDefaultModelId,
+	geminiCliModels,
 	claudeCodeModels,
 	claudeCodeDefaultModelId,
 	doubaoModels,

label export const getModelsByProvider = ({

 				defaultModel: qwenCodeDefaultModelId,
 			}
 		}
+		case "gemini-cli": {
+			return {
+				models: geminiCliModels,
+				defaultModel: geminiDefaultModelId,
+			}
+		}
 		case "anthropic": {
 			return {
 				models: anthropicModels,

file webview-ui/src/components/settings/ApiOptions.tsx
label import {

 	claudeCodeDefaultModelId,
 	qwenCodeDefaultModelId,
 	geminiDefaultModelId,
+	geminiCliDefaultModelId,
 	deepSeekDefaultModelId,
 	moonshotDefaultModelId,
 	// kilocode_change start

label import {

 	VSCodeLM,
 	XAI,
 	// kilocode_change start
+	GeminiCli,
 	VirtualQuotaFallbackProvider,
 	Synthetic,
 	OvhCloudAiEndpoints,

label const ApiOptions = ({

 				lmstudio: { field: "lmStudioModelId" },
 				// kilocode_change start

+				"gemini-cli": { field: "apiModelId", default: geminiCliDefaultModelId },
 				synthetic: { field: "apiModelId", default: syntheticDefaultModelId },
 				ovhcloud: { field: "ovhCloudAiEndpointsModelId", default: ovhCloudAiEndpointsDefaultModelId },
 				inception: { field: "inceptionLabsModelId", default: inceptionDefaultModelId },

label const ApiOptions = ({

 
 		// kilocode_change start
 		// Providers that don't have documentation pages yet
-		const excludedProviders = ["moonshot", "chutes", "cerebras", "litellm", "zai", "qwen-code", "minimax"]
+		const excludedProviders = [
+			"gemini-cli",
+			"moonshot",
+			"chutes",
+			"cerebras",
+			"litellm",
+			"zai",
+			"qwen-code",
+			"minimax",
+		]
 
 		// Skip documentation link when the provider is excluded because documentation is not available
 		if (excludedProviders.includes(selectedProvider)) {

label const ApiOptions = ({

 			)}
 
 			{/* kilocode_change start */}
+			{selectedProvider === "gemini-cli" && (
+				<GeminiCli apiConfiguration={apiConfiguration} setApiConfigurationField={setApiConfigurationField} />
+			)}
+
 			{selectedProvider === "virtual-quota-fallback" && (
 				<VirtualQuotaFallbackProvider
 					apiConfiguration={apiConfiguration}

file webview-ui/src/components/settings/constants.ts
label import {

 	moonshotModels,
 	// kilocode_change start
 	// geminiModels,
+	geminiCliModels,
 	// kilocode_change end
 	mistralModels,
 	openAiNativeModels,

label export const MODELS_BY_PROVIDER: Partial<Record<ProviderName, Record<string, Mod

 	moonshot: moonshotModels,
 	// kilocode_change start
 	// gemini: geminiModels,
+	"gemini-cli": geminiCliModels,
 	// kilocode_change end
 	mistral: mistralModels,
 	"openai-native": openAiNativeModels,

label export const PROVIDERS = [

 	// kilocode_change start
 	{ value: "zenmux", label: "ZenMux" },
 	{ value: "inception", label: "Inception", proxy: false },
+	{ value: "gemini-cli", label: "Gemini CLI", proxy: false },
 	{ value: "virtual-quota-fallback", label: "Virtual Quota Fallback", proxy: false },
 	{ value: "synthetic", label: "Synthetic", proxy: false },
 	{ value: "ovhcloud", label: "OVHcloud AI Endpoints", proxy: false },

file webview-ui/src/components/settings/providers/GeminiCli.tsx

+import { VSCodeTextField } from "@vscode/webview-ui-toolkit/react"
+import { useCallback } from "react"
+import { inputEventTransform } from "../transforms"
+
+import type { ProviderSettings } from "@roo-code/types"
+
+interface GeminiCliProps {
+	readonly apiConfiguration: ProviderSettings
+	readonly setApiConfigurationField: (field: keyof ProviderSettings, value: ProviderSettings[keyof ProviderSettings]) => void
+}
+
+export const GeminiCli = ({ apiConfiguration, setApiConfigurationField }: GeminiCliProps) => {
+	const handleInputChange = useCallback(
+		<K extends keyof ProviderSettings, E>(
+			field: K,
+			transform: (event: E) => ProviderSettings[K] = inputEventTransform,
+		) =>
+			(event: E | Event) => {
+				setApiConfigurationField(field, transform(event as E))
+			},
+		[setApiConfigurationField],
+	)
+
+	return (
+    <>
+      <VSCodeTextField
+        value={apiConfiguration?.geminiCliOAuthPath || ""}
+        onInput={handleInputChange("geminiCliOAuthPath")}
+        placeholder="~/.gemini/oauth_creds.json"
+        className="w-full">
+        <label className="block font-medium mb-1">
+          OAuth Credentials Path (optional)
+        </label>
+      </VSCodeTextField>
+      <VSCodeTextField
+        value={apiConfiguration?.geminiCliProjectId || ""}
+        onInput={handleInputChange("geminiCliProjectId")}
+        placeholder="gen-lang-client-0123456789"
+        className="w-full">
+        <label className="block font-medium mb-1">
+          Cloud Project ID (optional)
+        </label>
+      </VSCodeTextField>
+    </>
+	)
+}

file webview-ui/src/components/settings/providers/index.ts
label export { VSCodeLM } from "./VSCodeLM"

 export { XAI } from "./XAI"
 // kilocode_change start
 export { OvhCloudAiEndpoints } from "./OvhCloud"
+export { GeminiCli } from "./GeminiCli"
 export { VirtualQuotaFallbackProvider } from "./VirtualQuotaFallbackProvider"
 export { Inception } from "./Inception"
 export { Synthetic } from "./Synthetic"

file webview-ui/src/components/ui/hooks/useSelectedModel.ts
label import {

 	geminiModels,
 	geminiDefaultModelId,
 	// kilocode_change start
+	geminiCliDefaultModelId,
+	geminiCliModels,
 	syntheticDefaultModelId,
 	ovhCloudAiEndpointsDefaultModelId,
 	inceptionDefaultModelId,

label function getSelectedModel({

 				info: routerModels["kilocode"][invalidOrDefaultModel],
 			}
 		}
+		case "gemini-cli": {
+			const id = apiConfiguration.apiModelId ?? geminiCliDefaultModelId
+			const info = geminiCliModels[id as keyof typeof geminiCliModels]
+			return { id, info }
+		}
 		case "virtual-quota-fallback": {
 			if (virtualQuotaActiveModel) {
 				return virtualQuotaActiveModel
